{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "da-ln-seq2seq-attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MPFdeFXvkDN-n1EcczQdLdNKglYF5mAa",
      "authorship_tag": "ABX9TyOMPQEXonBAnCgmzlPFSj4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyab1111/MultiLexNorm-Challenge/blob/main/Danish/da_ln_seq2seq_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqWmsiyccsZW"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#Importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxv-Z8ac0JX"
      },
      "source": [
        "# Both train and test set are in the root data directory\n",
        "train_path = '/content/drive/MyDrive/NLP/Lexical Normalisation/Multilexnorm Challenge/Danish/da.train.norm.txt'\n",
        "test_path = '/content/drive/MyDrive/NLP/Lexical Normalisation/Multilexnorm Challenge/Danish/da.train.norm.txt'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ1idDXEdCW1"
      },
      "source": [
        "# Parameters for our model\n",
        "INPUT_COLUMN = 'input'\n",
        "TARGET_COLUMN = 'target'\n",
        "TARGET_FOR_INPUT = 'target_for_input'\n",
        "NUM_SAMPLES = 20000 #40000\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM=1024 #512\n",
        "\n",
        "BATCH_SIZE = 64  # Batch size for training.\n",
        "EPOCHS = 10  # Number of epochs to train for.\n",
        "\n",
        "ATTENTION_FUNC='general'\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsKjEgn3dFB3"
      },
      "source": [
        "# Some function to preprocess the text data, taken from the Neural machine translation with attention tutorial\n",
        "# in Tensorflow\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    ''' Preprocess the input text w applying lowercase, removing accents, \n",
        "    creating a space between a word and the punctuation following it and \n",
        "    replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    Input:\n",
        "        - w: a string, input text\n",
        "    Output:\n",
        "        - a string, the cleaned text\n",
        "    '''\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \":\", \"#\",\"@\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿:#@]+\", \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence so that the model know when to start and stop predicting.\n",
        "    #w = '<start> ' + w + ' <end>'\n",
        "    \n",
        "    return w"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFFP1V42dKru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ef9701-404c-4c33-8424-4991b79726c6"
      },
      "source": [
        "# Load the dataset: sentence in english, sentence in spanish \n",
        "df=pd.read_csv(train_path, sep=\"\\t\", header=None, names=[INPUT_COLUMN,TARGET_COLUMN], usecols=[0,1], \n",
        "               nrows=NUM_SAMPLES)\n",
        "# Preprocess the input data\n",
        "input_data=df[INPUT_COLUMN].apply(lambda x : str(x)).tolist()\n",
        "# Preprocess and include the end of sentence token to the target text\n",
        "target_data=df[TARGET_COLUMN].apply(lambda x : str(x)+ ' <eos>').tolist()\n",
        "# Preprocess and include a start of setence token to the input text to the decoder, it is rigth shifted\n",
        "target_input_data=df[TARGET_COLUMN].apply(lambda x : '<sos> '+ str(x)).tolist()\n",
        "\n",
        "print(input_data[:5])\n",
        "print(target_data[:5])\n",
        "print(target_input_data[:5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['jeg', 'er', 'træt', 'af', 'GoT']\n",
            "['jeg <eos>', 'er <eos>', 'træt <eos>', 'af <eos>', 'GoT <eos>']\n",
            "['<sos> jeg', '<sos> er', '<sos> træt', '<sos> af', '<sos> GoT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omD7crl7dZE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682f2617-48dd-415c-8373-7e7a0f83a727"
      },
      "source": [
        "#Delete the dataframe and release the memory (if it is possible)\n",
        "del df\n",
        "gc.collect()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdnvYHKifmk6",
        "outputId": "4fcd9e4c-3904-4bb8-915c-61bd9520cc05"
      },
      "source": [
        "# Create a tokenizer for the input texts and fit it to them \n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_inputs.fit_on_texts(input_data)\n",
        "# Tokenize and transform input texts to sequence of integers\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_data)\n",
        "# Claculate the max length\n",
        "input_max_len = max(len(s) for s in input_sequences)\n",
        "print('Max Input Length: ', input_max_len)\n",
        "# Show some example of tokenize sentences, useful to check the tokenization\n",
        "print(input_data[1000])\n",
        "print(input_sequences[1000])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Input Length:  1\n",
            "Subtle\n",
            "[1016]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsOWObRKfpj8",
        "outputId": "9dfcb966-01c4-4ef3-c489-0dde853290a2"
      },
      "source": [
        "# Create a tokenizer for the output texts and fit it to them \n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_data)\n",
        "tokenizer_outputs.fit_on_texts(target_input_data)\n",
        "# Tokenize and transform output texts to sequence of integers\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_data)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_input_data)\n",
        "\n",
        "# determine maximum length output sequence\n",
        "target_max_len = max(len(s) for s in target_sequences)\n",
        "print('Max Target Length: ', target_max_len)\n",
        "\n",
        "print(target_data[1000])\n",
        "print(target_sequences[1000])\n",
        "print(target_input_data[1000])\n",
        "print(target_sequences_inputs[1000])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Target Length:  4\n",
            "Subtle <eos>\n",
            "[1005, 1]\n",
            "<sos> Subtle\n",
            "[2, 1005]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1yd1KKof1et",
        "outputId": "fc6a1c19-bcb3-43fa-bab9-242c210f60ba"
      },
      "source": [
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output and input words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3167 unique input tokens.\n",
            "Found 3125 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOWDncfVf-I4",
        "outputId": "9c3b29d7-6ac2-46db-d9ff-58cdbc55a5bb"
      },
      "source": [
        "# pad the input sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=input_max_len, padding='post')\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "# pad the decoder input sequences\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=target_max_len, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "# pad the target output sequences\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=target_max_len, padding='post')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_inputs.shape: (9392, 1)\n",
            "encoder_inputs[0]: [8]\n",
            "decoder_inputs[0]: [ 2 10  0  0]\n",
            "decoder_inputs.shape: (9392, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5dfmtTLgI6b"
      },
      "source": [
        "# Define a dataset \n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (encoder_inputs, decoder_inputs, decoder_targets))\n",
        "dataset = dataset.shuffle(len(input_data)).batch(\n",
        "    BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j29xmjNwgNh2"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Define the embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # Define the RNN layer, LSTM\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            hidden_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, input_sequence, states):\n",
        "        # Embed the input\n",
        "        embed = self.embedding(input_sequence)\n",
        "        # Call the LSTM unit\n",
        "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
        "\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        # Return a all 0s initial states\n",
        "        return (tf.zeros([batch_size, self.hidden_dim]),\n",
        "                tf.zeros([batch_size, self.hidden_dim]))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Van2hY5TgZal"
      },
      "source": [
        "class LuongAttention(tf.keras.Model):\n",
        "    def __init__(self, rnn_size, attention_func):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.attention_func = attention_func\n",
        "\n",
        "        if attention_func not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(\n",
        "                'Attention score must be either dot, general or concat.')\n",
        "\n",
        "        if attention_func == 'general':\n",
        "            # General score function\n",
        "            self.wa = tf.keras.layers.Dense(rnn_size)\n",
        "        elif attention_func == 'concat':\n",
        "            # Concat score function\n",
        "            self.wa = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
        "            self.va = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, decoder_output, encoder_output):\n",
        "        if self.attention_func == 'dot':\n",
        "            # Dot score function: decoder_output (dot) encoder_output\n",
        "            # decoder_output has shape: (batch_size, 1, rnn_size)\n",
        "            # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
        "            # => score has shape: (batch_size, 1, max_len)\n",
        "            score = tf.matmul(decoder_output, encoder_output, transpose_b=True) # (batch_size, 1, max_len)\n",
        "        elif self.attention_func == 'general':\n",
        "            # General score function: decoder_output (dot) (Wa (dot) encoder_output)\n",
        "            # decoder_output has shape: (batch_size, 1, rnn_size)\n",
        "            # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
        "            # => score has shape: (batch_size, 1, max_len)\n",
        "            score = tf.matmul(decoder_output, self.wa(\n",
        "                encoder_output), transpose_b=True) #(batch_size, 1, max_len)\n",
        "        elif self.attention_func == 'concat':\n",
        "            # Concat score function: va (dot) tanh(Wa (dot) concat(decoder_output + encoder_output))\n",
        "            # Decoder output must be broadcasted to encoder output's shape first\n",
        "            decoder_output = tf.tile(\n",
        "                decoder_output, [1, encoder_output.shape[1], 1]) #shape (batch size, max len,hidden_dim)\n",
        "\n",
        "            # Concat => Wa => va\n",
        "            # (batch_size, max_len, 2 * rnn_size) => (batch_size, max_len, rnn_size) => (batch_size, max_len, 1)\n",
        "            score = self.va(\n",
        "                self.wa(tf.concat((decoder_output, encoder_output), axis=-1))) # (batch_size, max len, 1)\n",
        "\n",
        "            # Transpose score vector to have the same shape as other two above\n",
        "            # (batch_size, max_len, 1) => (batch_size, 1, max_len)\n",
        "            score = tf.transpose(score, [0, 2, 1]) #(batch_size, 1, max_len)\n",
        "\n",
        "        # alignment a_t = softmax(score)\n",
        "        alignment = tf.keras.activations.softmax(score, axis=-1) #(batch_size, 1, max_len)\n",
        "        \n",
        "        # context vector c_t is the weighted average sum of encoder output\n",
        "        context = tf.matmul(alignment, encoder_output) # (batch_size, 1, hidden_dim)\n",
        "\n",
        "        return context, alignment\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGu4NIYegoni"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, attention_func):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.attention = LuongAttention(hidden_dim, attention_func)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            hidden_dim, return_sequences=True, return_state=True)\n",
        "        self.wc = tf.keras.layers.Dense(hidden_dim, activation='tanh')\n",
        "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, input_sequence, state, encoder_output):\n",
        "        # Remember that the input to the decoder\n",
        "        # is now a batch of one-word sequences,\n",
        "        # which means that its shape is (batch_size, 1)\n",
        "        embed = self.embedding(input_sequence)\n",
        "\n",
        "        # Therefore, the lstm_out has shape (batch_size, 1, hidden_dim)\n",
        "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
        "\n",
        "        # Use self.attention to compute the context and alignment vectors\n",
        "        # context vector's shape: (batch_size, 1, hidden_dim)\n",
        "        # alignment vector's shape: (batch_size, 1, source_length)\n",
        "        context, alignment = self.attention(lstm_out, encoder_output)\n",
        "\n",
        "        # Combine the context vector and the LSTM output\n",
        "        # Before combined, both have shape of (batch_size, 1, hidden_dim),\n",
        "        # so let's squeeze the axis 1 first\n",
        "        # After combined, it will have shape of (batch_size, 2 * hidden_dim)\n",
        "        lstm_out = tf.concat(\n",
        "            [tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
        "\n",
        "        # lstm_out now has shape (batch_size, hidden_dim)\n",
        "        lstm_out = self.wc(lstm_out)\n",
        "\n",
        "        # Finally, it is converted back to vocabulary space: (batch_size, vocab_size)\n",
        "        logits = self.ws(lstm_out)\n",
        "\n",
        "        return logits, state_h, state_c, alignment"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt-IlB7wgq-Z"
      },
      "source": [
        "#Set the length of the input and output vocabulary\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "#Create the encoder\n",
        "encoder = Encoder(num_words_inputs, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "decoder = Decoder(num_words_output, EMBEDDING_DIM, HIDDEN_DIM, ATTENTION_FUNC)\n",
        "\n",
        "# Call the encoder and then the decoder\n",
        "initial_state = encoder.init_states(1)\n",
        "encoder_outputs = encoder(tf.constant([[1]]), initial_state)\n",
        "decoder_outputs = decoder(tf.constant(\n",
        "    [[1]]), encoder_outputs[1:], encoder_outputs[0])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx2scPOTg-Fr"
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True)\n",
        "    # Mask padding values, they do not have to compute for loss\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    # Calculate the loss value\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    # y_pred shape is batch_size, seq length, vocab size\n",
        "    # y_true shape is batch_size, seq length\n",
        "    pred_values = K.cast(K.argmax(y_pred, axis=-1), dtype='int32')\n",
        "    correct = K.cast(K.equal(y_true, pred_values), dtype='float32')\n",
        "\n",
        "    # 0 is padding, don't include those\n",
        "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
        "    n_correct = K.sum(mask * correct)\n",
        "    n_total = K.sum(mask)\n",
        "  \n",
        "    return n_correct / n_total"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zd2nxa6gua3"
      },
      "source": [
        "@tf.function\n",
        "def train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer):\n",
        "    ''' A training step, train a batch of the data and return the loss value reached\n",
        "        Input:\n",
        "        - input_seq: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the input sequence\n",
        "        - target_seq_out: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the target seq, our target sequence\n",
        "        - target_seq_in: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the input sequence to the decoder, we use Teacher Forcing\n",
        "        - en_initial_states: tuple of arrays of shape [batch_size, hidden_dim].\n",
        "            the initial state of the encoder\n",
        "        - optimizer: a tf.keras.optimizers.\n",
        "        Output:\n",
        "        - loss: loss value\n",
        "        \n",
        "    '''\n",
        "    loss = 0.\n",
        "    acc = 0.\n",
        "    logits = None\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        en_outputs = encoder(input_seq, en_initial_states)\n",
        "        en_states = en_outputs[1:]\n",
        "        de_state_h, de_state_c = en_states\n",
        "\n",
        "        # We need to create a loop to iterate through the target sequences\n",
        "        for i in range(target_seq_out.shape[1]):\n",
        "            # Input to the decoder must have shape of (batch_size, length)\n",
        "            # so we need to expand one dimension\n",
        "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
        "            logit, de_state_h, de_state_c, _ = decoder(\n",
        "                decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
        "\n",
        "            # The loss is now accumulated through the whole batch\n",
        "            loss += loss_func(target_seq_out[:, i], logit)\n",
        "            # Store the logits to calculate the accuracy\n",
        "            logit = K.expand_dims(logit, axis=1)\n",
        "            if logits is None:\n",
        "                logits = logit\n",
        "            else:\n",
        "                logits = K.concatenate((logits,logit), axis=1)\n",
        "        # Calculate the accuracy for the batch data        \n",
        "        acc = accuracy_fn(target_seq_out, logits)\n",
        "    # Update the parameters and the optimizer\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss / target_seq_out.shape[1], acc"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQaHg6tThOAy"
      },
      "source": [
        "# Create the main train function\n",
        "def main_train(encoder, decoder, dataset, n_epochs, batch_size, optimizer, checkpoint, checkpoint_prefix):\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    for e in range(n_epochs):\n",
        "        # Get the initial time\n",
        "        start = time.time()\n",
        "        # Get the initial state for the encoder\n",
        "        en_initial_states = encoder.init_states(batch_size)\n",
        "        # For every batch data\n",
        "        for batch, (input_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "            # Train and get the loss value \n",
        "            loss, accuracy = train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer)\n",
        "        \n",
        "            if batch % 100 == 0:\n",
        "                # Store the loss and accuracy values\n",
        "                losses.append(loss)\n",
        "                accuracies.append(accuracy)\n",
        "                print('Epoch {} Batch {} Loss {:.4f} Acc:{:.4f}'.format(e + 1, batch, loss.numpy(), accuracy.numpy()))\n",
        "                \n",
        "        # saving (checkpoint) the model every 2 epochs\n",
        "        if (e + 1) % 2 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "        print('Time taken for 1 epoch {:.4f} sec\\n'.format(time.time() - start))\n",
        "        \n",
        "    return losses, accuracies"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BoDgIZrg_ti",
        "outputId": "a99c7ddc-f97b-49bd-c647-36f10c719017"
      },
      "source": [
        "# Create an Adam optimizer and clips gradients by norm\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
        "# Create a checkpoint object to save the model\n",
        "checkpoint_dir = './training_ckpt_seq2seq_att'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "losses, accuracies = main_train(encoder, decoder, dataset, EPOCHS, BATCH_SIZE, optimizer, checkpoint, checkpoint_prefix)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.0238 Acc:0.0000\n",
            "Epoch 1 Batch 100 Loss 1.2213 Acc:0.5859\n",
            "Time taken for 1 epoch 16.3662 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.2382 Acc:0.6434\n",
            "Epoch 2 Batch 100 Loss 0.8172 Acc:0.7656\n",
            "Time taken for 1 epoch 8.6871 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.7753 Acc:0.7674\n",
            "Epoch 3 Batch 100 Loss 0.7515 Acc:0.7969\n",
            "Time taken for 1 epoch 7.9521 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.4716 Acc:0.8594\n",
            "Epoch 4 Batch 100 Loss 0.5293 Acc:0.8438\n",
            "Time taken for 1 epoch 8.3628 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.2777 Acc:0.9062\n",
            "Epoch 5 Batch 100 Loss 0.4411 Acc:0.8359\n",
            "Time taken for 1 epoch 7.9246 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2870 Acc:0.8906\n",
            "Epoch 6 Batch 100 Loss 0.3627 Acc:0.8450\n",
            "Time taken for 1 epoch 8.3337 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0878 Acc:0.9766\n",
            "Epoch 7 Batch 100 Loss 0.1584 Acc:0.9062\n",
            "Time taken for 1 epoch 7.9428 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0628 Acc:0.9766\n",
            "Epoch 8 Batch 100 Loss 0.0825 Acc:0.9531\n",
            "Time taken for 1 epoch 8.3315 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0119 Acc:1.0000\n",
            "Epoch 9 Batch 100 Loss 0.0464 Acc:0.9766\n",
            "Time taken for 1 epoch 7.9278 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0211 Acc:0.9922\n",
            "Epoch 10 Batch 100 Loss 0.0049 Acc:1.0000\n",
            "Time taken for 1 epoch 8.3667 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "FsyTWuhYhIi7",
        "outputId": "3c663614-bbde-40bb-b25c-ce76aef6307d"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "# plot some data\n",
        "ax1.plot(losses, label='loss')\n",
        "#plt.plot(results.history['val_loss'], label='val_loss')\n",
        "ax1.set_title('Training Loss')\n",
        "ax1.legend()\n",
        "# accuracies\n",
        "ax2.plot(accuracies, label='acc')\n",
        "#plt.plot(results.history['val_accuracy_fn'], label='val_acc')\n",
        "ax2.set_title('Training Accuracy')\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my_TtcF4hsG1",
        "outputId": "b4b776f2-870e-4abf-8a83-5b36d09a778b"
      },
      "source": [
        "# Create an Adam optimizer and clips gradients by norm\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
        "# Create a checkpoint object to save the model\n",
        "checkpoint_dir = './training_ckpt_seq2seq_att'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0d2ac37f10>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwmhbpkjh2bj"
      },
      "source": [
        "def predict_seq2seq_att(input_text, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
        "    if input_text is None:\n",
        "        input_text = input_data[np.random.choice(len(input_data))]\n",
        "    print(input_text)\n",
        "    # Tokenize the input text\n",
        "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
        "    # Pad the sentence\n",
        "    input_seq = pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
        "    # Get the encoder initial states\n",
        "    en_initial_states = encoder.init_states(1)\n",
        "    # Get the encoder outputs or hidden states\n",
        "    en_outputs = encoder(tf.constant(input_seq), en_initial_states)\n",
        "    # Set the decoder input to the sos token\n",
        "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
        "    # Set the initial hidden states of the decoder to the hidden states of the encoder\n",
        "    de_state_h, de_state_c = en_outputs[1:]\n",
        "    \n",
        "    out_words = []\n",
        "    alignments = []\n",
        "\n",
        "    while True:\n",
        "        # Get the decoder with attention output\n",
        "        de_output, de_state_h, de_state_c, alignment = decoder(\n",
        "            de_input, (de_state_h, de_state_c), en_outputs[0])\n",
        "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
        "        # Detokenize the output\n",
        "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
        "        # Save the aligment matrix\n",
        "        alignments.append(alignment.numpy())\n",
        "\n",
        "        if out_words[-1] == '<eos>' or len(out_words) >= 20:\n",
        "            break\n",
        "    # Join the output words\n",
        "    print(' '.join(out_words))\n",
        "    return np.array(alignments), input_text.split(' '), out_words"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG_9gshbh5dN",
        "outputId": "e9e8c054-e63b-4a3b-e981-adea7bb98004"
      },
      "source": [
        "n_predictions=50\n",
        "test_sents = input_data[0:(0+n_predictions)]\n",
        "for i, test_sent in enumerate(test_sents):\n",
        "  alignments, source, prediction = predict_seq2seq_att(test_sent, input_max_len, tokenizer_inputs, \n",
        "                                                     word2idx_outputs, idx2word_outputs)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jeg\n",
            "jeg <eos>\n",
            "er\n",
            "er <eos>\n",
            "træt\n",
            "træt <eos>\n",
            "af\n",
            "af <eos>\n",
            "GoT\n",
            "got <eos>\n",
            ",\n",
            ", <eos>\n",
            "jeg\n",
            "jeg <eos>\n",
            "synes\n",
            "synes <eos>\n",
            "ikke\n",
            "ikke <eos>\n",
            "Tyrion\n",
            "tyrion <eos>\n",
            "er\n",
            "er <eos>\n",
            "sjov\n",
            "sjov <eos>\n",
            "længere\n",
            "længere <eos>\n",
            ",\n",
            ", <eos>\n",
            "jeg\n",
            "jeg <eos>\n",
            "synes\n",
            "synes <eos>\n",
            "Daenaerys\n",
            "daenaerys <eos>\n",
            "er\n",
            "er <eos>\n",
            "meget\n",
            "meget <eos>\n",
            "mindre\n",
            "mindre <eos>\n",
            "klog\n",
            "klog <eos>\n",
            "og\n",
            "og <eos>\n",
            "sej\n",
            "sej <eos>\n",
            "end\n",
            "end <eos>\n",
            "hun\n",
            "hun <eos>\n",
            "plejede\n",
            "plejede <eos>\n",
            "at\n",
            "at <eos>\n",
            "være\n",
            "være <eos>\n",
            ",\n",
            ", <eos>\n",
            "og\n",
            "og <eos>\n",
            "jeg\n",
            "jeg <eos>\n",
            "kan\n",
            "kan <eos>\n",
            "ikke\n",
            "ikke <eos>\n",
            "komme\n",
            "komme <eos>\n",
            "mig\n",
            "mig <eos>\n",
            "over\n",
            "over <eos>\n",
            "at\n",
            "at <eos>\n",
            "The\n",
            "the <eos>\n",
            "White\n",
            "white <eos>\n",
            "Walkers\n",
            "walkers <eos>\n",
            "bare\n",
            "bare <eos>\n",
            "var\n",
            "var <eos>\n",
            "en\n",
            "en <eos>\n",
            "plotdevice\n",
            "plotdevice <eos>\n",
            "for\n",
            "for <eos>\n",
            "at\n",
            "at <eos>\n",
            "sætte\n",
            "sætte <eos>\n",
            "hende\n",
            "hende <eos>\n",
            "ligeligt\n",
            "ligeligt <eos>\n",
            "op\n",
            "op <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG8AQxX_h76m"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}