{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "en-ln-seq2seq-attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1O65q9ftI2KjTWgq0cOI2tjil_xKCy4Mz",
      "authorship_tag": "ABX9TyNbmRnfcBLdWFVK8rcCKEGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyab1111/MultiLexNorm-Challenge/blob/main/English/en_ln_seq2seq_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqWmsiyccsZW"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#Importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxv-Z8ac0JX"
      },
      "source": [
        "# Both train and test set are in the root data directory\n",
        "train_path = '/content/drive/MyDrive/NLP/Lexical Normalisation/Multilexnorm Challenge/English/train.norm.txt'\n",
        "test_path = '/content/drive/MyDrive/NLP/Lexical Normalisation/Multilexnorm Challenge/English/train.norm.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ1idDXEdCW1"
      },
      "source": [
        "# Parameters for our model\n",
        "INPUT_COLUMN = 'input'\n",
        "TARGET_COLUMN = 'target'\n",
        "TARGET_FOR_INPUT = 'target_for_input'\n",
        "NUM_SAMPLES = 20000 #40000\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM=1024 #512\n",
        "\n",
        "BATCH_SIZE = 64  # Batch size for training.\n",
        "EPOCHS = 10  # Number of epochs to train for.\n",
        "\n",
        "ATTENTION_FUNC='general'\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsKjEgn3dFB3"
      },
      "source": [
        "# Some function to preprocess the text data, taken from the Neural machine translation with attention tutorial\n",
        "# in Tensorflow\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    ''' Preprocess the input text w applying lowercase, removing accents, \n",
        "    creating a space between a word and the punctuation following it and \n",
        "    replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    Input:\n",
        "        - w: a string, input text\n",
        "    Output:\n",
        "        - a string, the cleaned text\n",
        "    '''\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \":\", \"#\",\"@\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿:#@]+\", \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence so that the model know when to start and stop predicting.\n",
        "    #w = '<start> ' + w + ' <end>'\n",
        "    \n",
        "    return w"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFFP1V42dKru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853414bd-9b6e-42e6-a8f9-fb0df2c9f18d"
      },
      "source": [
        "# Load the dataset: sentence in english, sentence in spanish \n",
        "df=pd.read_csv(train_path, sep=\"\\t\", header=None, names=[INPUT_COLUMN,TARGET_COLUMN], usecols=[0,1], \n",
        "               nrows=NUM_SAMPLES)\n",
        "# Preprocess the input data\n",
        "input_data=df[INPUT_COLUMN].apply(lambda x : str(x)).tolist()\n",
        "# Preprocess and include the end of sentence token to the target text\n",
        "target_data=df[TARGET_COLUMN].apply(lambda x : str(x)+ ' <eos>').tolist()\n",
        "# Preprocess and include a start of setence token to the input text to the decoder, it is rigth shifted\n",
        "target_input_data=df[TARGET_COLUMN].apply(lambda x : '<sos> '+ str(x)).tolist()\n",
        "\n",
        "print(input_data[:5])\n",
        "print(target_data[:5])\n",
        "print(target_input_data[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rt', '@teddyferrari1', ':', '\\t', 'ah']\n",
            "['rt <eos>', '@teddyferrari1 <eos>', ': <eos>', 'nan <eos>', 'ah <eos>']\n",
            "['<sos> rt', '<sos> @teddyferrari1', '<sos> :', '<sos> nan', '<sos> ah']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omD7crl7dZE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd550725-bb14-46b9-8d42-c3ed325d2ee9"
      },
      "source": [
        "#Delete the dataframe and release the memory (if it is possible)\n",
        "del df\n",
        "gc.collect()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdnvYHKifmk6",
        "outputId": "7a3e632f-558a-473a-c7e6-3c808438ae2d"
      },
      "source": [
        "# Create a tokenizer for the input texts and fit it to them \n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_inputs.fit_on_texts(input_data)\n",
        "# Tokenize and transform input texts to sequence of integers\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_data)\n",
        "# Claculate the max length\n",
        "input_max_len = max(len(s) for s in input_sequences)\n",
        "print('Max Input Length: ', input_max_len)\n",
        "# Show some example of tokenize sentences, useful to check the tokenization\n",
        "print(input_data[1000])\n",
        "print(input_sequences[1000])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Input Length:  1\n",
            "oppa\n",
            "[524]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsOWObRKfpj8",
        "outputId": "92c56f86-e95d-4eda-922b-7183f7c15af2"
      },
      "source": [
        "# Create a tokenizer for the output texts and fit it to them \n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_data)\n",
        "tokenizer_outputs.fit_on_texts(target_input_data)\n",
        "# Tokenize and transform output texts to sequence of integers\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_data)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_input_data)\n",
        "\n",
        "# determine maximum length output sequence\n",
        "target_max_len = max(len(s) for s in target_sequences)\n",
        "print('Max Target Length: ', target_max_len)\n",
        "\n",
        "print(target_data[1000])\n",
        "print(target_sequences[1000])\n",
        "print(target_input_data[1000])\n",
        "print(target_sequences_inputs[1000])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Target Length:  8\n",
            "oppa <eos>\n",
            "[523, 1]\n",
            "<sos> oppa\n",
            "[2, 523]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1yd1KKof1et",
        "outputId": "f644ddab-e0a6-491e-d525-981fd5cd8b24"
      },
      "source": [
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output and input words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6970 unique input tokens.\n",
            "Found 6570 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOWDncfVf-I4",
        "outputId": "d5b7d697-7706-410f-b83b-0777d05f5d6b"
      },
      "source": [
        "# pad the input sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=input_max_len, padding='post')\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "# pad the decoder input sequences\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=target_max_len, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "# pad the target output sequences\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=target_max_len, padding='post')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_inputs.shape: (20000, 1)\n",
            "encoder_inputs[0]: [3]\n",
            "decoder_inputs[0]: [2 5 0 0 0 0 0 0]\n",
            "decoder_inputs.shape: (20000, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5dfmtTLgI6b"
      },
      "source": [
        "# Define a dataset \n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (encoder_inputs, decoder_inputs, decoder_targets))\n",
        "dataset = dataset.shuffle(len(input_data)).batch(\n",
        "    BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j29xmjNwgNh2"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Define the embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # Define the RNN layer, LSTM\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            hidden_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, input_sequence, states):\n",
        "        # Embed the input\n",
        "        embed = self.embedding(input_sequence)\n",
        "        # Call the LSTM unit\n",
        "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
        "\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        # Return a all 0s initial states\n",
        "        return (tf.zeros([batch_size, self.hidden_dim]),\n",
        "                tf.zeros([batch_size, self.hidden_dim]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Van2hY5TgZal"
      },
      "source": [
        "class LuongAttention(tf.keras.Model):\n",
        "    def __init__(self, rnn_size, attention_func):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.attention_func = attention_func\n",
        "\n",
        "        if attention_func not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(\n",
        "                'Attention score must be either dot, general or concat.')\n",
        "\n",
        "        if attention_func == 'general':\n",
        "            # General score function\n",
        "            self.wa = tf.keras.layers.Dense(rnn_size)\n",
        "        elif attention_func == 'concat':\n",
        "            # Concat score function\n",
        "            self.wa = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
        "            self.va = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, decoder_output, encoder_output):\n",
        "        if self.attention_func == 'dot':\n",
        "            # Dot score function: decoder_output (dot) encoder_output\n",
        "            # decoder_output has shape: (batch_size, 1, rnn_size)\n",
        "            # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
        "            # => score has shape: (batch_size, 1, max_len)\n",
        "            score = tf.matmul(decoder_output, encoder_output, transpose_b=True) # (batch_size, 1, max_len)\n",
        "        elif self.attention_func == 'general':\n",
        "            # General score function: decoder_output (dot) (Wa (dot) encoder_output)\n",
        "            # decoder_output has shape: (batch_size, 1, rnn_size)\n",
        "            # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
        "            # => score has shape: (batch_size, 1, max_len)\n",
        "            score = tf.matmul(decoder_output, self.wa(\n",
        "                encoder_output), transpose_b=True) #(batch_size, 1, max_len)\n",
        "        elif self.attention_func == 'concat':\n",
        "            # Concat score function: va (dot) tanh(Wa (dot) concat(decoder_output + encoder_output))\n",
        "            # Decoder output must be broadcasted to encoder output's shape first\n",
        "            decoder_output = tf.tile(\n",
        "                decoder_output, [1, encoder_output.shape[1], 1]) #shape (batch size, max len,hidden_dim)\n",
        "\n",
        "            # Concat => Wa => va\n",
        "            # (batch_size, max_len, 2 * rnn_size) => (batch_size, max_len, rnn_size) => (batch_size, max_len, 1)\n",
        "            score = self.va(\n",
        "                self.wa(tf.concat((decoder_output, encoder_output), axis=-1))) # (batch_size, max len, 1)\n",
        "\n",
        "            # Transpose score vector to have the same shape as other two above\n",
        "            # (batch_size, max_len, 1) => (batch_size, 1, max_len)\n",
        "            score = tf.transpose(score, [0, 2, 1]) #(batch_size, 1, max_len)\n",
        "\n",
        "        # alignment a_t = softmax(score)\n",
        "        alignment = tf.keras.activations.softmax(score, axis=-1) #(batch_size, 1, max_len)\n",
        "        \n",
        "        # context vector c_t is the weighted average sum of encoder output\n",
        "        context = tf.matmul(alignment, encoder_output) # (batch_size, 1, hidden_dim)\n",
        "\n",
        "        return context, alignment\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGu4NIYegoni"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, attention_func):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.attention = LuongAttention(hidden_dim, attention_func)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            hidden_dim, return_sequences=True, return_state=True)\n",
        "        self.wc = tf.keras.layers.Dense(hidden_dim, activation='tanh')\n",
        "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, input_sequence, state, encoder_output):\n",
        "        # Remember that the input to the decoder\n",
        "        # is now a batch of one-word sequences,\n",
        "        # which means that its shape is (batch_size, 1)\n",
        "        embed = self.embedding(input_sequence)\n",
        "\n",
        "        # Therefore, the lstm_out has shape (batch_size, 1, hidden_dim)\n",
        "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
        "\n",
        "        # Use self.attention to compute the context and alignment vectors\n",
        "        # context vector's shape: (batch_size, 1, hidden_dim)\n",
        "        # alignment vector's shape: (batch_size, 1, source_length)\n",
        "        context, alignment = self.attention(lstm_out, encoder_output)\n",
        "\n",
        "        # Combine the context vector and the LSTM output\n",
        "        # Before combined, both have shape of (batch_size, 1, hidden_dim),\n",
        "        # so let's squeeze the axis 1 first\n",
        "        # After combined, it will have shape of (batch_size, 2 * hidden_dim)\n",
        "        lstm_out = tf.concat(\n",
        "            [tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
        "\n",
        "        # lstm_out now has shape (batch_size, hidden_dim)\n",
        "        lstm_out = self.wc(lstm_out)\n",
        "\n",
        "        # Finally, it is converted back to vocabulary space: (batch_size, vocab_size)\n",
        "        logits = self.ws(lstm_out)\n",
        "\n",
        "        return logits, state_h, state_c, alignment"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt-IlB7wgq-Z"
      },
      "source": [
        "#Set the length of the input and output vocabulary\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "#Create the encoder\n",
        "encoder = Encoder(num_words_inputs, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "decoder = Decoder(num_words_output, EMBEDDING_DIM, HIDDEN_DIM, ATTENTION_FUNC)\n",
        "\n",
        "# Call the encoder and then the decoder\n",
        "initial_state = encoder.init_states(1)\n",
        "encoder_outputs = encoder(tf.constant([[1]]), initial_state)\n",
        "decoder_outputs = decoder(tf.constant(\n",
        "    [[1]]), encoder_outputs[1:], encoder_outputs[0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx2scPOTg-Fr"
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True)\n",
        "    # Mask padding values, they do not have to compute for loss\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    # Calculate the loss value\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    # y_pred shape is batch_size, seq length, vocab size\n",
        "    # y_true shape is batch_size, seq length\n",
        "    pred_values = K.cast(K.argmax(y_pred, axis=-1), dtype='int32')\n",
        "    correct = K.cast(K.equal(y_true, pred_values), dtype='float32')\n",
        "\n",
        "    # 0 is padding, don't include those\n",
        "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
        "    n_correct = K.sum(mask * correct)\n",
        "    n_total = K.sum(mask)\n",
        "  \n",
        "    return n_correct / n_total"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zd2nxa6gua3"
      },
      "source": [
        "@tf.function\n",
        "def train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer):\n",
        "    ''' A training step, train a batch of the data and return the loss value reached\n",
        "        Input:\n",
        "        - input_seq: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the input sequence\n",
        "        - target_seq_out: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the target seq, our target sequence\n",
        "        - target_seq_in: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the input sequence to the decoder, we use Teacher Forcing\n",
        "        - en_initial_states: tuple of arrays of shape [batch_size, hidden_dim].\n",
        "            the initial state of the encoder\n",
        "        - optimizer: a tf.keras.optimizers.\n",
        "        Output:\n",
        "        - loss: loss value\n",
        "        \n",
        "    '''\n",
        "    loss = 0.\n",
        "    acc = 0.\n",
        "    logits = None\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        en_outputs = encoder(input_seq, en_initial_states)\n",
        "        en_states = en_outputs[1:]\n",
        "        de_state_h, de_state_c = en_states\n",
        "\n",
        "        # We need to create a loop to iterate through the target sequences\n",
        "        for i in range(target_seq_out.shape[1]):\n",
        "            # Input to the decoder must have shape of (batch_size, length)\n",
        "            # so we need to expand one dimension\n",
        "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
        "            logit, de_state_h, de_state_c, _ = decoder(\n",
        "                decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
        "\n",
        "            # The loss is now accumulated through the whole batch\n",
        "            loss += loss_func(target_seq_out[:, i], logit)\n",
        "            # Store the logits to calculate the accuracy\n",
        "            logit = K.expand_dims(logit, axis=1)\n",
        "            if logits is None:\n",
        "                logits = logit\n",
        "            else:\n",
        "                logits = K.concatenate((logits,logit), axis=1)\n",
        "        # Calculate the accuracy for the batch data        \n",
        "        acc = accuracy_fn(target_seq_out, logits)\n",
        "    # Update the parameters and the optimizer\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss / target_seq_out.shape[1], acc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQaHg6tThOAy"
      },
      "source": [
        "# Create the main train function\n",
        "def main_train(encoder, decoder, dataset, n_epochs, batch_size, optimizer, checkpoint, checkpoint_prefix):\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    for e in range(n_epochs):\n",
        "        # Get the initial time\n",
        "        start = time.time()\n",
        "        # Get the initial state for the encoder\n",
        "        en_initial_states = encoder.init_states(batch_size)\n",
        "        # For every batch data\n",
        "        for batch, (input_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "            # Train and get the loss value \n",
        "            loss, accuracy = train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer)\n",
        "        \n",
        "            if batch % 100 == 0:\n",
        "                # Store the loss and accuracy values\n",
        "                losses.append(loss)\n",
        "                accuracies.append(accuracy)\n",
        "                print('Epoch {} Batch {} Loss {:.4f} Acc:{:.4f}'.format(e + 1, batch, loss.numpy(), accuracy.numpy()))\n",
        "                \n",
        "        # saving (checkpoint) the model every 2 epochs\n",
        "        if (e + 1) % 2 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "        print('Time taken for 1 epoch {:.4f} sec\\n'.format(time.time() - start))\n",
        "        \n",
        "    return losses, accuracies"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BoDgIZrg_ti",
        "outputId": "f29d305a-3c93-4e08-f1b1-dc4ed3cd236b"
      },
      "source": [
        "# Create an Adam optimizer and clips gradients by norm\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
        "# Create a checkpoint object to save the model\n",
        "checkpoint_dir = './training_ckpt_seq2seq_att'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "losses, accuracies = main_train(encoder, decoder, dataset, EPOCHS, BATCH_SIZE, optimizer, checkpoint, checkpoint_prefix)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1975 Acc:0.0000\n",
            "Epoch 1 Batch 100 Loss 1.0999 Acc:0.5191\n",
            "Epoch 1 Batch 200 Loss 0.7251 Acc:0.6047\n",
            "Epoch 1 Batch 300 Loss 0.5739 Acc:0.6719\n",
            "Time taken for 1 epoch 23.8765 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.4907 Acc:0.7231\n",
            "Epoch 2 Batch 100 Loss 0.4379 Acc:0.7500\n",
            "Epoch 2 Batch 200 Loss 0.4801 Acc:0.7422\n",
            "Epoch 2 Batch 300 Loss 0.4593 Acc:0.7734\n",
            "Time taken for 1 epoch 13.5844 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.3992 Acc:0.8000\n",
            "Epoch 3 Batch 100 Loss 0.3619 Acc:0.7984\n",
            "Epoch 3 Batch 200 Loss 0.4084 Acc:0.7891\n",
            "Epoch 3 Batch 300 Loss 0.2360 Acc:0.8760\n",
            "Time taken for 1 epoch 13.0036 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.2815 Acc:0.8203\n",
            "Epoch 4 Batch 100 Loss 0.2834 Acc:0.8125\n",
            "Epoch 4 Batch 200 Loss 0.2783 Acc:0.8203\n",
            "Epoch 4 Batch 300 Loss 0.2615 Acc:0.8672\n",
            "Time taken for 1 epoch 13.5439 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1230 Acc:0.9062\n",
            "Epoch 5 Batch 100 Loss 0.0932 Acc:0.9141\n",
            "Epoch 5 Batch 200 Loss 0.1529 Acc:0.8769\n",
            "Epoch 5 Batch 300 Loss 0.2053 Acc:0.8359\n",
            "Time taken for 1 epoch 13.0764 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0674 Acc:0.9375\n",
            "Epoch 6 Batch 100 Loss 0.0825 Acc:0.9070\n",
            "Epoch 6 Batch 200 Loss 0.1019 Acc:0.8828\n",
            "Epoch 6 Batch 300 Loss 0.0794 Acc:0.8984\n",
            "Time taken for 1 epoch 13.6291 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0235 Acc:0.9844\n",
            "Epoch 7 Batch 100 Loss 0.0436 Acc:0.9609\n",
            "Epoch 7 Batch 200 Loss 0.0216 Acc:0.9766\n",
            "Epoch 7 Batch 300 Loss 0.0144 Acc:0.9922\n",
            "Time taken for 1 epoch 13.1227 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0030 Acc:1.0000\n",
            "Epoch 8 Batch 100 Loss 0.0195 Acc:0.9844\n",
            "Epoch 8 Batch 200 Loss 0.0280 Acc:0.9766\n",
            "Epoch 8 Batch 300 Loss 0.0108 Acc:0.9845\n",
            "Time taken for 1 epoch 13.5710 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0008 Acc:1.0000\n",
            "Epoch 9 Batch 100 Loss 0.0013 Acc:1.0000\n",
            "Epoch 9 Batch 200 Loss 0.0008 Acc:1.0000\n",
            "Epoch 9 Batch 300 Loss 0.0247 Acc:0.9774\n",
            "Time taken for 1 epoch 13.0675 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0097 Acc:0.9922\n",
            "Epoch 10 Batch 100 Loss 0.0003 Acc:1.0000\n",
            "Epoch 10 Batch 200 Loss 0.0254 Acc:0.9766\n",
            "Epoch 10 Batch 300 Loss 0.0007 Acc:1.0000\n",
            "Time taken for 1 epoch 13.6040 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "FsyTWuhYhIi7",
        "outputId": "52678af7-b770-4109-a9d0-120d0dc3119a"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "# plot some data\n",
        "ax1.plot(losses, label='loss')\n",
        "#plt.plot(results.history['val_loss'], label='val_loss')\n",
        "ax1.set_title('Training Loss')\n",
        "ax1.legend()\n",
        "# accuracies\n",
        "ax2.plot(accuracies, label='acc')\n",
        "#plt.plot(results.history['val_accuracy_fn'], label='val_acc')\n",
        "ax2.set_title('Training Accuracy')\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my_TtcF4hsG1",
        "outputId": "4cc8e281-76fc-4e98-d10d-2600c461e204"
      },
      "source": [
        "# Create an Adam optimizer and clips gradients by norm\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
        "# Create a checkpoint object to save the model\n",
        "checkpoint_dir = './training_ckpt_seq2seq_att'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa035a4e890>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwmhbpkjh2bj"
      },
      "source": [
        "def predict_seq2seq_att(input_text, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
        "    if input_text is None:\n",
        "        input_text = input_data[np.random.choice(len(input_data))]\n",
        "    print(input_text)\n",
        "    # Tokenize the input text\n",
        "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
        "    # Pad the sentence\n",
        "    input_seq = pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
        "    # Get the encoder initial states\n",
        "    en_initial_states = encoder.init_states(1)\n",
        "    # Get the encoder outputs or hidden states\n",
        "    en_outputs = encoder(tf.constant(input_seq), en_initial_states)\n",
        "    # Set the decoder input to the sos token\n",
        "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
        "    # Set the initial hidden states of the decoder to the hidden states of the encoder\n",
        "    de_state_h, de_state_c = en_outputs[1:]\n",
        "    \n",
        "    out_words = []\n",
        "    alignments = []\n",
        "\n",
        "    while True:\n",
        "        # Get the decoder with attention output\n",
        "        de_output, de_state_h, de_state_c, alignment = decoder(\n",
        "            de_input, (de_state_h, de_state_c), en_outputs[0])\n",
        "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
        "        # Detokenize the output\n",
        "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
        "        # Save the aligment matrix\n",
        "        alignments.append(alignment.numpy())\n",
        "\n",
        "        if out_words[-1] == '<eos>' or len(out_words) >= 20:\n",
        "            break\n",
        "    # Join the output words\n",
        "    print(' '.join(out_words))\n",
        "    return np.array(alignments), input_text.split(' '), out_words"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG_9gshbh5dN",
        "outputId": "9c956399-1b0b-4d13-962f-7e693dece26e"
      },
      "source": [
        "n_predictions=50\n",
        "test_sents = input_data[15005:(15005+n_predictions)]\n",
        "for i, test_sent in enumerate(test_sents):\n",
        "  alignments, source, prediction = predict_seq2seq_att(test_sent, input_max_len, tokenizer_inputs, \n",
        "                                                     word2idx_outputs, idx2word_outputs)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bordering\n",
            "bordering <eos>\n",
            "femme\n",
            "femme <eos>\n",
            "lol\n",
            "lol <eos>\n",
            "yea\n",
            "yeah <eos>\n",
            "im\n",
            "i'm <eos>\n",
            "not\n",
            "not <eos>\n",
            "gonna\n",
            "going to <eos>\n",
            "be\n",
            "be <eos>\n",
            "happy\n",
            "happy <eos>\n",
            "bout\n",
            "about <eos>\n",
            "bosh\n",
            "bosh <eos>\n",
            "this\n",
            "this <eos>\n",
            "the\n",
            "the <eos>\n",
            "least\n",
            "least <eos>\n",
            "he\n",
            "he <eos>\n",
            "culd\n",
            "could <eos>\n",
            "do\n",
            "do <eos>\n",
            "after\n",
            "after <eos>\n",
            "how\n",
            "how <eos>\n",
            "he\n",
            "he <eos>\n",
            "been\n",
            "been <eos>\n",
            "playin\n",
            "playing <eos>\n",
            "@nashgrier\n",
            "@nashgrier <eos>\n",
            "wtf\n",
            "wtf <eos>\n",
            "how\n",
            "how <eos>\n",
            "did\n",
            "did <eos>\n",
            "you\n",
            "you <eos>\n",
            "find\n",
            "find <eos>\n",
            "my\n",
            "my <eos>\n",
            "twitter\n",
            "twitter <eos>\n",
            "nash\n",
            "nash <eos>\n",
            "i\n",
            "i <eos>\n",
            "loce\n",
            "love <eos>\n",
            "you\n",
            "you <eos>\n",
            "so\n",
            "so <eos>\n",
            "much\n",
            "much <eos>\n",
            "@dougbenson\n",
            "@dougbenson <eos>\n",
            "is\n",
            "is <eos>\n",
            "gona\n",
            "gonna <eos>\n",
            "do\n",
            "do <eos>\n",
            "a\n",
            "a <eos>\n",
            "comicon\n",
            "comicon <eos>\n",
            "but\n",
            "but <eos>\n",
            "its\n",
            "its <eos>\n",
            "gona\n",
            "gonna <eos>\n",
            "be\n",
            "be <eos>\n",
            "called\n",
            "called <eos>\n",
            "cronicon\n",
            "cronicon <eos>\n",
            "lol\n",
            "lol <eos>\n",
            "rt\n",
            "rt <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG8AQxX_h76m"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}